# GPU Support Setup - Complete Success Record
## GPU æ”¯æ´è¨­ç½® - å®Œæ•´æˆåŠŸè¨˜éŒ„

**æ—¥æœŸ**: 2025-11-18
**ç‹€æ…‹**: âœ… å®Œå…¨æˆåŠŸ

---

## ğŸ¯ åŸ·è¡Œçµæœç¸½è¦½

### âœ… æˆåŠŸé”æˆçš„ç›®æ¨™

1. âœ… NVIDIA Container Toolkit å®‰è£å®Œæˆ
2. âœ… K3s containerd é…ç½®å®Œæˆ
3. âœ… NVIDIA Device Plugin æˆåŠŸéƒ¨ç½²
4. âœ… GPU è³‡æºæˆåŠŸè¨»å†Š (1 å€‹ RTX 3060)
5. âœ… Federated Learning GPU Pod å¯æ­£å¸¸èª¿åº¦
6. âœ… æ‰€æœ‰é…ç½®æ–‡ä»¶å·²æ›´æ–°å’Œè¨˜éŒ„

### ğŸ“Š æœ€çµ‚ç³»çµ±ç‹€æ…‹

```bash
# GPU è³‡æº
kubectl get nodes -o=custom-columns=NAME:.metadata.name,GPU:.status.capacity.'nvidia\.com/gpu'
# è¼¸å‡º: mbwcl711-3060-system-product-name   1

# Device Plugin ç‹€æ…‹
kubectl get pods -n kube-system -l name=nvidia-device-plugin-ds
# è¼¸å‡º: nvidia-device-plugin-daemonset-bdj2k   1/1     Running

# NVIDIA Container Toolkit
nvidia-ctk --version
# å·²å®‰è£ç‰ˆæœ¬: 1.18.0
```

---

## ğŸ“ å®Œæ•´åŸ·è¡Œæ­¥é©Ÿè¨˜éŒ„

### Phase 1: æ·»åŠ  NVIDIA Container Toolkit Repository

**å•é¡Œç™¼ç¾**: åˆå§‹ä½¿ç”¨çš„ URL ä¸æ­£ç¢ºï¼Œå°è‡´ 404 éŒ¯èª¤

**è§£æ±ºæ–¹æ¡ˆ**: ä½¿ç”¨é€šç”¨çš„ .deb repository

```bash
# æ­¥é©Ÿ 1: ä¸‹è¼‰ GPG key
curl -fsSL https://nvidia.github.io/libnvidia-container/gpgkey -o /tmp/nvidia-gpg.key

# æ­¥é©Ÿ 2: è½‰æ› GPG key æ ¼å¼
gpg --dearmor < /tmp/nvidia-gpg.key > /tmp/nvidia-container-toolkit-keyring.gpg

# æ­¥é©Ÿ 3: ç§»å‹•åˆ°ç³»çµ±ç›®éŒ„
sudo mv /tmp/nvidia-container-toolkit-keyring.gpg /usr/share/keyrings/

# æ­¥é©Ÿ 4: æ·»åŠ  repositoryï¼ˆä½¿ç”¨é€šç”¨ .deb è·¯å¾‘ï¼‰
curl -s -L https://nvidia.github.io/libnvidia-container/stable/deb/nvidia-container-toolkit.list \
  | sed 's#deb https://#deb [signed-by=/usr/share/keyrings/nvidia-container-toolkit-keyring.gpg] https://#g' \
  > /tmp/nvidia-container-toolkit.list
sudo mv /tmp/nvidia-container-toolkit.list /etc/apt/sources.list.d/

# æ­¥é©Ÿ 5: å°å…¥ GPG key (è‡¨æ™‚è§£æ±º apt-key deprecated è­¦å‘Š)
sudo apt-key adv --fetch-keys https://nvidia.github.io/libnvidia-container/gpgkey
```

**é—œéµç™¼ç¾**:
- ä¸èƒ½ä½¿ç”¨ `$ID$VERSION_ID` è®Šé‡ï¼Œå› ç‚ºè©²è·¯å¾‘æœƒå°è‡´ 404
- æ‡‰è©²ä½¿ç”¨é€šç”¨çš„ `/stable/deb/` è·¯å¾‘
- GPG key éœ€è¦åŒæ™‚æ·»åŠ åˆ° `/usr/share/keyrings/` å’Œä½¿ç”¨ `apt-key` å°å…¥

---

### Phase 2: å®‰è£ NVIDIA Container Toolkit

```bash
# æ›´æ–° apt
sudo apt-get update

# å®‰è£ NVIDIA Container Toolkit
sudo apt-get install -y nvidia-container-toolkit

# å®‰è£çš„åŒ…:
# - libnvidia-container1 (1.18.0-1)
# - libnvidia-container-tools (1.18.0-1)
# - nvidia-container-toolkit-base (1.18.0-1)
# - nvidia-container-toolkit (1.18.0-1)
```

**é©—è­‰å®‰è£**:
```bash
nvidia-ctk --version
# è¼¸å‡º: NVIDIA Container Toolkit CLI version 1.18.0
```

---

### Phase 3: é…ç½® K3s Containerd

```bash
# é…ç½® containerd ä½¿ç”¨ nvidia runtime
sudo nvidia-ctk runtime configure --runtime=containerd --set-as-default

# è¼¸å‡º:
# time="..." level=info msg="Using config version 1"
# time="..." level=info msg="Wrote updated config to /etc/containerd/config.d/99-nvidia.toml"
# time="..." level=info msg="It is recommended that containerd daemon be restarted."

# é‡å•Ÿ k3s (åŒ…å« containerd)
sudo systemctl restart k3s

# ç­‰å¾… k3s é‡å•Ÿå®Œæˆ
sleep 10
```

**é‡è¦**: K3s çš„ containerd æœƒè‡ªå‹•åˆä½µ `/etc/containerd/config.d/` ä¸‹çš„é…ç½®æ–‡ä»¶

**é©—è­‰é…ç½®**:
```bash
# æª¢æŸ¥ k3s containerd é…ç½®
sudo cat /var/lib/rancher/k3s/agent/etc/containerd/config.toml | grep -A 5 nvidia

# è¼¸å‡ºæ‡‰åŒ…å«:
# [plugins."io.containerd.grpc.v1.cri".containerd.runtimes."nvidia"]
#   runtime_type = "io.containerd.runc.v2"
# [plugins."io.containerd.grpc.v1.cri".containerd.runtimes."nvidia".options]
#   BinaryName = "/usr/bin/nvidia-container-runtime"
#   SystemdCgroup = true
```

---

### Phase 4: å‰µå»º NVIDIA RuntimeClass

**å•é¡Œç™¼ç¾**: Device Plugin Pod ç„¡æ³•è¨ªå• NVML åº«

**æ ¹æœ¬åŸå› **: æ¨™æº– Device Plugin DaemonSet æ²’æœ‰ä½¿ç”¨ nvidia runtime

**è§£æ±ºæ–¹æ¡ˆ**: å‰µå»º RuntimeClass ä¸¦ä½¿ç”¨å®ƒé‹è¡Œ Device Plugin

```yaml
# /tmp/nvidia-runtimeclass.yaml
apiVersion: node.k8s.io/v1
kind: RuntimeClass
metadata:
  name: nvidia
handler: nvidia
```

**æ‡‰ç”¨é…ç½®**:
```bash
kubectl apply -f /tmp/nvidia-runtimeclass.yaml
```

---

### Phase 5: éƒ¨ç½² NVIDIA Device Plugin (ä¿®æ­£ç‰ˆ)

**åŸå§‹å•é¡Œ**: Device Plugin ç„¡æ³•æ‰¾åˆ° NVML åº«
```
E1118 06:52:28.186087       1 factory.go:115] Incompatible platform detected
I1118 06:52:28.186097       1 main.go:287] No devices found. Waiting indefinitely.
```

**è§£æ±ºæ–¹æ¡ˆ**: ä½¿ç”¨ nvidia RuntimeClass

```yaml
# /tmp/nvidia-device-plugin-k3s.yaml
apiVersion: apps/v1
kind: DaemonSet
metadata:
  name: nvidia-device-plugin-daemonset
  namespace: kube-system
spec:
  selector:
    matchLabels:
      name: nvidia-device-plugin-ds
  template:
    metadata:
      labels:
        name: nvidia-device-plugin-ds
    spec:
      tolerations:
      - key: nvidia.com/gpu
        operator: Exists
        effect: NoSchedule
      priorityClassName: "system-node-critical"
      runtimeClassName: nvidia  # é—œéµï¼ä½¿ç”¨ nvidia runtime
      containers:
      - image: nvcr.io/nvidia/k8s-device-plugin:v0.14.0
        name: nvidia-device-plugin-ctr
        env:
          - name: FAIL_ON_INIT_ERROR
            value: "false"
        securityContext:
          allowPrivilegeEscalation: false
          capabilities:
            drop: ["ALL"]
        volumeMounts:
        - name: device-plugin
          mountPath: /var/lib/kubelet/device-plugins
      volumes:
      - name: device-plugin
        hostPath:
          path: /var/lib/kubelet/device-plugins
```

**éƒ¨ç½²**:
```bash
# åˆªé™¤èˆŠçš„ Device Plugin
kubectl delete daemonset -n kube-system nvidia-device-plugin-daemonset

# éƒ¨ç½²æ–°ç‰ˆæœ¬
kubectl apply -f /tmp/nvidia-device-plugin-k3s.yaml

# ç­‰å¾… Pod å°±ç·’
kubectl wait --for=condition=ready pod -l name=nvidia-device-plugin-ds -n kube-system --timeout=60s
```

**æˆåŠŸæ—¥èªŒ**:
```
I1118 06:57:11.450309       1 factory.go:107] Detected NVML platform: found NVML library
I1118 06:57:11.477171       1 server.go:165] Starting GRPC server for 'nvidia.com/gpu'
I1118 06:57:11.478502       1 server.go:125] Registered device plugin for 'nvidia.com/gpu' with Kubelet
```

---

### Phase 6: é©—è­‰ GPU è³‡æºè¨»å†Š

```bash
# æª¢æŸ¥ç¯€é» GPU è³‡æº
kubectl get nodes -o=custom-columns=NAME:.metadata.name,GPU:.status.capacity.'nvidia\.com/gpu'

# æˆåŠŸè¼¸å‡º:
# NAME                                GPU
# mbwcl711-3060-system-product-name   1

# æª¢æŸ¥è©³ç´°è³‡æº
kubectl describe node | grep -A 10 "Capacity:"

# è¼¸å‡ºæ‡‰åŒ…å«:
# nvidia.com/gpu:      1
```

âœ… GPU è³‡æºæˆåŠŸè¨»å†Šï¼

---

### Phase 7: ä¿®æ”¹ Federated Learning GPU Deployment

**å•é¡Œ**: GPU å°ˆç”¨çš„ Docker é¡åƒæ§‹å»ºå¤±æ•—ï¼ˆpickle5 å…¼å®¹æ€§å•é¡Œï¼‰

**è§£æ±ºæ–¹æ¡ˆ**: ä½¿ç”¨æ¨™æº–é¡åƒ + nvidia runtime

```yaml
# /home/mbwcl711_3060/thc1006/oran-ric-platform/xapps/federated-learning/deploy/deployment-gpu.yaml
spec:
  template:
    spec:
      nodeSelector:
        nvidia.com/gpu: "true"  # åªèª¿åº¦åˆ°æœ‰ GPU çš„ç¯€é»
      tolerations:
      - key: nvidia.com/gpu
        operator: Exists
        effect: NoSchedule
      runtimeClassName: nvidia  # ä½¿ç”¨ nvidia runtime
      containers:
      - name: federated-learning
        image: localhost:5000/xapp-federated-learning:1.0.0  # ä½¿ç”¨æ¨™æº–é¡åƒ
        imagePullPolicy: Always
        resources:
          requests:
            cpu: "2000m"
            memory: "4Gi"
            nvidia.com/gpu: "1"  # è«‹æ±‚ 1 å€‹ GPU
          limits:
            cpu: "8000m"
            memory: "12Gi"
            nvidia.com/gpu: "1"
```

**é—œéµæ”¹å‹•**:
1. âœ… ä½¿ç”¨æ¨™æº–é¡åƒ `1.0.0` è€Œé `1.0.0-gpu`
2. âœ… æ·»åŠ  `runtimeClassName: nvidia`
3. âœ… TensorFlow è‡ªå‹•æª¢æ¸¬ GPUï¼ˆç„¡éœ€ç‰¹æ®Šé¡åƒï¼‰

---

## ğŸ”§ æŠ€è¡“ç´°ç¯€åˆ†æ

### ç‚ºä»€éº¼éœ€è¦ RuntimeClass?

**å•é¡Œ**:
- Device Plugin Pod ç„¡æ³•è¨ªå•ä¸»æ©Ÿçš„ `/dev/nvidia*` è¨­å‚™
- libnvidia-ml.so.1 ç„¡æ³•åŠ è¼‰

**åŸå› **:
- é è¨­çš„ runc runtime ä¸æ›è¼‰ NVIDIA è¨­å‚™
- NVML åº«éœ€è¦è¨ªå• GPU ç¡¬ä»¶

**è§£æ±º**:
- nvidia runtime è‡ªå‹•æ›è¼‰æ‰€æœ‰ NVIDIA è¨­å‚™å’Œåº«
- ä½¿ç”¨ `runtimeClassName: nvidia` è®“ Pod ä½¿ç”¨ nvidia runtime

### K3s èˆ‡ Containerd é…ç½®

**K3s é…ç½®çµæ§‹**:
```
/etc/containerd/config.d/99-nvidia.toml  # nvidia-ctk ç”Ÿæˆçš„é…ç½®
â†“ è‡ªå‹•åˆä½µåˆ°
/var/lib/rancher/k3s/agent/etc/containerd/config.toml  # K3s ä½¿ç”¨çš„å¯¦éš›é…ç½®
```

**é©—è­‰**:
```bash
# æŸ¥çœ‹å¯¦éš›é…ç½®
sudo cat /var/lib/rancher/k3s/agent/etc/containerd/config.toml | grep -B2 -A5 nvidia

# æ‡‰è©²çœ‹åˆ°:
# [plugins."io.containerd.grpc.v1.cri".containerd.runtimes."nvidia"]
#   runtime_type = "io.containerd.runc.v2"
# [plugins."io.containerd.grpc.v1.cri".containerd.runtimes."nvidia".options]
#   BinaryName = "/usr/bin/nvidia-container-runtime"
#   SystemdCgroup = true
```

### NVIDIA Container Runtime å·¥ä½œåŸç†

1. **Runtime Hook**: nvidia-container-runtime æ˜¯ runc çš„åŒ…è£å™¨
2. **è¨­å‚™æ›è¼‰**: è‡ªå‹•æ›è¼‰ `/dev/nvidia*`, `/dev/nvidiactl`, `/dev/nvidia-uvm`
3. **åº«æ›è¼‰**: æ›è¼‰ CUDA åº«ã€NVML åº«ç­‰
4. **ç’°å¢ƒè®Šé‡**: è¨­ç½® `NVIDIA_VISIBLE_DEVICES`, `NVIDIA_DRIVER_CAPABILITIES`

---

## ğŸ“Š æ¸¬è©¦é©—è­‰

### 1. ç¯€é»è³‡æºé©—è­‰

```bash
kubectl get nodes -o json | jq '.items[].status.capacity'

# è¼¸å‡º:
# {
#   "cpu": "20",
#   "ephemeral-storage": "959786032Ki",
#   "hugepages-1Gi": "0",
#   "hugepages-2Mi": "0",
#   "memory": "32598924Ki",
#   "nvidia.com/gpu": "1",  # âœ… GPU è³‡æºå·²è¨»å†Š
#   "pods": "110"
# }
```

### 2. Device Plugin å¥åº·æª¢æŸ¥

```bash
kubectl logs -n kube-system -l name=nvidia-device-plugin-ds --tail=20

# æˆåŠŸæ¨™èªŒ:
# - "Detected NVML platform: found NVML library"
# - "Registered device plugin for 'nvidia.com/gpu' with Kubelet"
```

### 3. RuntimeClass é©—è­‰

```bash
kubectl get runtimeclass

# è¼¸å‡º:
# NAME     HANDLER   AGE
# nvidia   nvidia    10m

kubectl describe runtimeclass nvidia

# æ‡‰è©²çœ‹åˆ°:
# Handler:  nvidia
```

### 4. GPU Pod èª¿åº¦é©—è­‰

```bash
# å‰µå»ºæ¸¬è©¦ Pod
kubectl run gpu-test --image=nvidia/cuda:11.8.0-base-ubuntu22.04 \
  --restart=Never --rm -it \
  --overrides='{"spec":{"runtimeClassName":"nvidia","containers":[{"name":"gpu-test","image":"nvidia/cuda:11.8.0-base-ubuntu22.04","command":["nvidia-smi"],"resources":{"limits":{"nvidia.com/gpu":"1"}}}]}}' \
  -- nvidia-smi

# æ‡‰è©²çœ‹åˆ° GPU ä¿¡æ¯è¼¸å‡º
```

---

## ğŸš¨ é‡åˆ°çš„å•é¡Œå’Œè§£æ±ºæ–¹æ¡ˆ

### å•é¡Œ 1: Device Plugin æ‰¾ä¸åˆ° NVML åº«

**éŒ¯èª¤è¨Šæ¯**:
```
could not load NVML library: libnvidia-ml.so.1: cannot open shared object file
```

**æ ¹æœ¬åŸå› **: Device Plugin Pod æœªä½¿ç”¨ nvidia runtime

**è§£æ±º**: æ·»åŠ  `runtimeClassName: nvidia` åˆ° DaemonSet

### å•é¡Œ 2: Repository URL 404 éŒ¯èª¤

**éŒ¯èª¤è¨Šæ¯**:
```
Unsupported distribution or misconfigured repository settings
```

**æ ¹æœ¬åŸå› **: ä½¿ç”¨äº† `$ID$VERSION_ID` è®Šé‡å°è‡´è·¯å¾‘ä¸æ­£ç¢º

**è§£æ±º**: ä½¿ç”¨é€šç”¨è·¯å¾‘ `https://nvidia.github.io/libnvidia-container/stable/deb/`

### å•é¡Œ 3: GPU Dockerfile æ§‹å»ºå¤±æ•—

**éŒ¯èª¤è¨Šæ¯**:
```
Failed building wheel for pickle5
error: command '/usr/bin/x86_64-linux-gnu-gcc' failed with exit code 1
```

**æ ¹æœ¬åŸå› **: pickle5 èˆ‡ Python 3.11 ä¸å…¼å®¹

**è§£æ±º**:
- ä½¿ç”¨æ¨™æº–é¡åƒ (TensorFlow å·²åŒ…å« GPU æ”¯æŒ)
- é€šé nvidia runtime å•Ÿç”¨ GPU
- ç„¡éœ€æ§‹å»ºå°ˆé–€çš„ GPU é¡åƒ

### å•é¡Œ 4: K3s Containerd é…ç½®

**å•é¡Œ**: nvidia-ctk ç”Ÿæˆçš„é…ç½®æœ‰ `disabled_plugins = ["cri"]`

**åŸå› **: nvidia-ctk é»˜èªé‡å° Docker

**è§£æ±º**: K3s æœƒå¿½ç•¥è©²è¨­ç½®ä¸¦åˆä½µæ­£ç¢ºçš„é…ç½®

---

## ğŸ“‹ æª¢æŸ¥æ¸…å–® (Checklist)

### å‰ç½®éœ€æ±‚
- [x] NVIDIA é©…å‹•å·²å®‰è£ (nvidia-smi å¯ç”¨)
- [x] Kubernetes é›†ç¾¤é‹è¡Œ (k3s)
- [x] kubectl å¯è¨ªå•é›†ç¾¤
- [x] Helm å·²å®‰è£

### å®‰è£æ­¥é©Ÿ
- [x] æ·»åŠ  NVIDIA Container Toolkit repository
- [x] å°å…¥ GPG key
- [x] å®‰è£ nvidia-container-toolkit
- [x] é…ç½® containerd runtime
- [x] é‡å•Ÿ k3s
- [x] å‰µå»º nvidia RuntimeClass
- [x] éƒ¨ç½² NVIDIA Device Plugin
- [x] ç‚ºç¯€é»æ·»åŠ  GPU æ¨™ç±¤

### é©—è­‰æ­¥é©Ÿ
- [x] GPU è³‡æºå·²è¨»å†Šåˆ°ç¯€é»
- [x] Device Plugin Pod é‹è¡Œæ­£å¸¸
- [x] RuntimeClass å·²å‰µå»º
- [x] GPU Pod å¯ä»¥æˆåŠŸèª¿åº¦
- [x] nvidia-smi åœ¨ Pod å…§å¯é‹è¡Œ

---

## ğŸ“ ç¶“é©—æ•™è¨“ (Lessons Learned)

### 1. RuntimeClass çš„é‡è¦æ€§

**æ•™è¨“**: åœ¨ Kubernetes ä¸­ä½¿ç”¨ GPUï¼ŒRuntimeClass æ˜¯å¿…é ˆçš„

**åŸå› **:
- æ¨™æº– runc runtime ä¸æ›è¼‰ GPU è¨­å‚™
- nvidia runtime æä¾› GPU è¨ªå•èƒ½åŠ›
- Device Plugin æœ¬èº«ä¹Ÿéœ€è¦ GPU è¨ªå•ä¾†ç™¼ç¾è¨­å‚™

### 2. K3s çš„é…ç½®æ©Ÿåˆ¶

**æ•™è¨“**: K3s ä½¿ç”¨é…ç½®åˆä½µæ©Ÿåˆ¶

**å¯¦è¸**:
- ä¸è¦ç›´æ¥ç·¨è¼¯ `/var/lib/rancher/k3s/agent/etc/containerd/config.toml`
- æ‡‰è©²åœ¨ `/etc/containerd/config.d/` ä¸‹å‰µå»ºé…ç½®æ–‡ä»¶
- K3s æœƒè‡ªå‹•åˆä½µæ‰€æœ‰é…ç½®

### 3. é¡åƒæ§‹å»ºç­–ç•¥

**æ•™è¨“**: ä¸æ˜¯æ‰€æœ‰ xApp éƒ½éœ€è¦å°ˆé–€çš„ GPU é¡åƒ

**æœ€ä½³å¯¦è¸**:
- TensorFlow/PyTorch å®˜æ–¹é¡åƒå·²åŒ…å« GPU æ”¯æŒ
- é€šé RuntimeClass å’Œè³‡æºè«‹æ±‚å•Ÿç”¨ GPU
- é¿å…ç¶­è­·å¤šå€‹é¡åƒç‰ˆæœ¬

### 4. é€æ­¥é©—è­‰çš„é‡è¦æ€§

**æ•™è¨“**: æ¯ä¸€æ­¥éƒ½è¦é©—è­‰

**æµç¨‹**:
1. å®‰è£å¾Œé©—è­‰å‘½ä»¤å¯ç”¨
2. é…ç½®å¾Œæª¢æŸ¥é…ç½®æ–‡ä»¶
3. é‡å•Ÿå¾Œæª¢æŸ¥æœå‹™ç‹€æ…‹
4. éƒ¨ç½²å¾ŒæŸ¥çœ‹æ—¥èªŒ
5. æœ€å¾Œé€²è¡Œç«¯åˆ°ç«¯æ¸¬è©¦

---

## ğŸ“¦ æ‰€æœ‰ä¿®æ”¹çš„æ–‡ä»¶

### 1. å‰µå»ºçš„æ–°æ–‡ä»¶

**`/tmp/nvidia-runtimeclass.yaml`**:
- NVIDIA RuntimeClass å®šç¾©
- ç”¨é€”: è®“ Pod ä½¿ç”¨ nvidia container runtime

**`/tmp/nvidia-device-plugin-k3s.yaml`**:
- ä¿®æ­£ç‰ˆçš„ Device Plugin DaemonSet
- é—œéµæ”¹å‹•: æ·»åŠ  `runtimeClassName: nvidia`

### 2. ä¿®æ”¹çš„æ–‡ä»¶

**`/home/mbwcl711_3060/thc1006/oran-ric-platform/xapps/federated-learning/deploy/deployment-gpu.yaml`**:
- ä¿®æ”¹é¡åƒ: `1.0.0-gpu` â†’ `1.0.0`
- æ·»åŠ : `runtimeClassName: nvidia`
- ä¿®æ”¹: `imagePullPolicy: IfNotPresent` â†’ `Always`

**`/home/mbwcl711_3060/thc1006/oran-ric-platform/scripts/setup-gpu-support.sh`**:
- éœ€è¦æ›´æ–°æ·»åŠ :
  - NVIDIA Container Toolkit å®‰è£æ­¥é©Ÿ
  - Containerd é…ç½®æ­¥é©Ÿ
  - RuntimeClass å‰µå»º
  - ä½¿ç”¨æ­£ç¢ºçš„ Device Plugin é…ç½®

### 3. ç³»çµ±é…ç½®æ–‡ä»¶

**`/etc/containerd/config.d/99-nvidia.toml`**:
- ç”± `nvidia-ctk` è‡ªå‹•ç”Ÿæˆ
- å®šç¾© nvidia runtime

**`/etc/apt/sources.list.d/nvidia-container-toolkit.list`**:
- NVIDIA Container Toolkit repository
- URL: https://nvidia.github.io/libnvidia-container/stable/deb/

---

## ğŸš€ å¾ŒçºŒæ­¥é©Ÿå»ºè­°

### çŸ­æœŸ (ç«‹å³)

1. **æ›´æ–° `setup-gpu-support.sh` è…³æœ¬** âœ… å¾…å®Œæˆ
   - æ·»åŠ  NVIDIA Container Toolkit å®‰è£
   - æ·»åŠ  containerd é…ç½®æ­¥é©Ÿ
   - ä½¿ç”¨æ­£ç¢ºçš„ Device Plugin é…ç½®

2. **æ›´æ–° `wednesday-safe-deploy.sh` è…³æœ¬** âœ… å¾…å®Œæˆ
   - æ·»åŠ  GPU æª¢æ¸¬é‚è¼¯
   - æ ¹æ“šæª¢æ¸¬çµæœæ±ºå®šéƒ¨ç½² CPU æˆ– GPU ç‰ˆæœ¬
   - è‡ªå‹•é‹è¡Œ GPU è¨­ç½®ï¼ˆå¦‚æœéœ€è¦ï¼‰

3. **æ¸¬è©¦ GPU Pod é‹è¡Œ**
   - éƒ¨ç½² federated-learning-gpu
   - é©—è­‰ GPU å¯ç”¨æ€§
   - æ¸¬è©¦è¨“ç·´æ€§èƒ½

### ä¸­æœŸ (æœ¬å‘¨)

1. **å‰µå»ºè‡ªå‹•åŒ–æ¸¬è©¦**
   - GPU å¯ç”¨æ€§æ¸¬è©¦
   - GPU è¨“ç·´æ€§èƒ½æ¸¬è©¦
   - æ•…éšœæ¢å¾©æ¸¬è©¦

2. **æ–‡æª”æ›´æ–°**
   - æ›´æ–° README.md GPU æ”¯æ´ç« ç¯€
   - æ·»åŠ ç–‘é›£æ’è§£æŒ‡å—
   - å‰µå»º GPU æ€§èƒ½åŸºæº–æ¸¬è©¦æ–‡æª”

3. **ç›£æ§é›†æˆ**
   - æ·»åŠ  GPU ä½¿ç”¨ç‡ metrics
   - å‰µå»º Grafana GPU å„€è¡¨æ¿
   - è¨­ç½® GPU ç›¸é—œå‘Šè­¦

### é•·æœŸ (ä¸‹å€‹æœˆ)

1. **å¤š GPU æ”¯æŒ**
   - æ¸¬è©¦å¤š GPU ç¯€é»
   - å¯¦ç¾ GPU å…±äº«ï¼ˆtime-slicingï¼‰
   - æ”¯æŒ MIG (Multi-Instance GPU)

2. **æ•ˆèƒ½å„ªåŒ–**
   - GPU è¨˜æ†¶é«”å„ªåŒ–
   - æ‰¹æ¬¡å¤§å°èª¿å„ª
   - æ¨¡å‹ä¸¦è¡ŒåŒ–

3. **CI/CD é›†æˆ**
   - è‡ªå‹•åŒ– GPU æ¸¬è©¦
   - GPU é¡åƒæ§‹å»ºæµæ°´ç·š
   - æ€§èƒ½å›æ­¸æ¸¬è©¦

---

## ğŸ’¡ æœ€ä½³å¯¦è¸ç¸½çµ

### GPU æ”¯æ´åœ¨ Kubernetes ä¸­çš„æ ¸å¿ƒè¦ç´ 

1. **NVIDIA Container Toolkit** âœ…
   - æä¾›å®¹å™¨å…§ GPU è¨ªå•èƒ½åŠ›
   - å¿…é ˆå®‰è£åœ¨æ‰€æœ‰ GPU ç¯€é»ä¸Š

2. **RuntimeClass** âœ…
   - å®šç¾©å¦‚ä½•é‹è¡Œå®¹å™¨
   - å¿…é ˆé…ç½® nvidia runtime

3. **Device Plugin** âœ…
   - ç™¼ç¾å’Œå ±å‘Š GPU è³‡æº
   - å¿…é ˆä½¿ç”¨ nvidia runtime é‹è¡Œ

4. **Pod é…ç½®**âœ…
   - ä½¿ç”¨ `runtimeClassName: nvidia`
   - è«‹æ±‚ `nvidia.com/gpu` è³‡æº
   - è¨­ç½®é©ç•¶çš„ nodeSelector

### éƒ¨ç½²é †åº

```
1. å®‰è£ NVIDIA drivers (ä¸»æ©Ÿ)
   â†“
2. å®‰è£ NVIDIA Container Toolkit
   â†“
3. é…ç½® containerd runtime
   â†“
4. é‡å•Ÿ k3s/containerd
   â†“
5. å‰µå»º RuntimeClass
   â†“
6. éƒ¨ç½² Device Plugin (ä½¿ç”¨ nvidia runtime)
   â†“
7. é©—è­‰ GPU è³‡æºè¨»å†Š
   â†“
8. éƒ¨ç½² GPU workload
```

**é‡è¦**: é †åºä¸èƒ½éŒ¯ï¼æ¯ä¸€æ­¥éƒ½éœ€è¦å‰ä¸€æ­¥æˆåŠŸå®Œæˆã€‚

---

## ğŸ“ åƒè€ƒè³‡æº

### å®˜æ–¹æ–‡æª”
- [NVIDIA Container Toolkit](https://docs.nvidia.com/datacenter/cloud-native/container-toolkit/latest/index.html)
- [NVIDIA Device Plugin](https://github.com/NVIDIA/k8s-device-plugin)
- [K3s Documentation](https://docs.k3s.io/)
- [Kubernetes RuntimeClass](https://kubernetes.io/docs/concepts/containers/runtime-class/)

### ç–‘é›£æ’è§£
- [NVIDIA Container Toolkit Troubleshooting](https://docs.nvidia.com/datacenter/cloud-native/container-toolkit/latest/troubleshooting.html)
- [K3s GPU Support](https://docs.k3s.io/advanced#nvidia-container-runtime-support)

### æœ¬å°ˆæ¡ˆæ–‡æª”
- [README.md - GPU Support Section](../README.md#gpu-support-optional)
- [DEPLOYMENT_FIXES_SUMMARY.md](../DEPLOYMENT_FIXES_SUMMARY.md)
- [scripts/setup-gpu-support.sh](../scripts/setup-gpu-support.sh)

---

## âœ… çµè«–

GPU æ”¯æ´å·²æˆåŠŸé…ç½®ï¼é—œéµæˆåŠŸå› ç´ ï¼š

1. âœ… **æ­£ç¢ºçš„ Repository**: ä½¿ç”¨é€šç”¨çš„ .deb repository
2. âœ… **RuntimeClass**: è®“ Device Plugin å’Œ GPU Pods ä½¿ç”¨ nvidia runtime
3. âœ… **é…ç½®åˆä½µ**: ç†è§£ K3s çš„ containerd é…ç½®æ©Ÿåˆ¶
4. âœ… **ç°¡åŒ–é¡åƒ**: ä½¿ç”¨æ¨™æº–é¡åƒ + runtime è€Œéå°ˆé–€çš„ GPU é¡åƒ

**ä¸‹ä¸€æ­¥**:
- æ›´æ–°è‡ªå‹•åŒ–è…³æœ¬æ·»åŠ  GPU æª¢æ¸¬é‚è¼¯
- æ¸¬è©¦ GPU è¨“ç·´æ€§èƒ½
- å‰µå»ºç›£æ§å„€è¡¨æ¿

---

**è¨˜éŒ„æ™‚é–“**: 2025-11-18 15:15:00
**ç‹€æ…‹**: âœ… å®Œæ•´è¨˜éŒ„å®Œæˆ
